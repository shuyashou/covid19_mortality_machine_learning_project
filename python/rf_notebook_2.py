# -*- coding: utf-8 -*-
"""RF_notebook_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eO8jc27NFOCMs-_U9DcCkCurHAulA2j_
"""

pip install shap

import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
from sklearn.model_selection import train_test_split, StratifiedKFold
import matplotlib.pyplot as plt
import seaborn as sns
import os
import numpy as np
import shap

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.feature_selection import RFECV
from sklearn.metrics import classification_report, accuracy_score
from sklearn.utils import shuffle
import time
from sklearn.inspection import permutation_importance
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, confusion_matrix, ConfusionMatrixDisplay

if torch.cuda.is_available():
  device = torch.device("cuda")
  print("Using GPU:", torch.cuda.get_device_name(0))
else:
  device = torch.device("cpu")
  print("CUDA is not availible. Using CPU instead.")

"""### Data Cleaning and Preprocessing
### Steps:
1. Drop any row with missing/unknown values. This reduces size of dataset from 106 M to 700 K.
2. Get rid of all columns related to date/time.
3. One-hot encode all categorical variables and keep only one of any column with binary outcome after one-hot encoding.
"""

df = pd.read_pickle("/content/drive/MyDrive/Machine Learning Project/Code/cdcdata.pkl")

for col in df.columns:
    print(col)

def one_hot_encoding_features(df, columns_to_encode):
  for column in columns_to_encode:
    if column not in df.columns:
      raise ValueError(f"Column '{column}' not found in DataFrame.")
  df_encoded = pd.get_dummies(df, columns=columns_to_encode)

  return df_encoded

"""Based on our previous model in the RF 1 notebook, we see that hospitalization status and ICU admission primarily drive the model, and we also have the issue of a data imbalance. We will try re-evaluating the model to consider hospitalization and ICU status as features and reduce the severe amount of non-death cases we have.

We will try:
1. Compute and evaluate a model without hospitalization status and perform feature analysis
2. Compute and evaluate a model without ICU admission status and perform feature analysis
3. Compute and evaluate a model without hospitalization & ICU admission status and perform feature analysis
4. Compute and evaluate a model without hospitalization & ICU admission status and perform feature analysis with balanced target values, with equal amount of death and non-death cases.

Overall, we see that removing features like hospitalization status and ICU admission status decrease the accuracy and AUC of our model, and especially cause a sharp decrease in PR values and our PR-AUC--the removal of the features combined with the data imbalance not helping matters. As far as feature analysis, we see that pre-existing conditions and old age are the features that drive our model when hosptialization and ICU is not present.

When the data is balanced, we see our precision and recall values increase, doing a very good job at minimizing false positives for death prediction and capturing actual death cases. PR-AUC goes up to 0.86, a sharp improvement. The PR values maximize when optimzing hyperparameters as well.

### 1. Dropping 'hosp_yn_Yes'
"""

columns_to_encode = ['current_status', 'sex', 'age_group', 'race_ethnicity_combined', 'hosp_yn', 'icu_yn', 'death_yn', 'medcond_yn']
df_encoded = one_hot_encoding_features(df, columns_to_encode)
cols_to_drop = ['cdc_case_earliest_dt', 'cdc_report_dt', 'pos_spec_dt', 'onset_dt', 'hosp_yn_No', 'icu_yn_No', 'death_yn_No', 'medcond_yn_No', 'hosp_yn_Yes']
df_dropped = df_encoded.drop(cols_to_drop, axis=1)
df = df_dropped

df.head()

for col in df.columns:
    print(col)

label_counts = df['death_yn_Yes'].value_counts()
print(label_counts)

label_proportions = label_counts / len(df)
print(label_proportions)

sns.countplot(x=df['death_yn_Yes'])
plt.title('Label Distribution')
plt.show()

#Proportion of each feature that is null.
df.isnull().sum()

df.shape

features = df.drop('death_yn_Yes', axis = 1)
labels = df['death_yn_Yes']
features_tensor = torch.tensor(features.values, dtype=torch.float32)
labels_tensor = torch.tensor(labels.values, dtype=torch.float32)

X = features_tensor.numpy()
y = labels_tensor.numpy()

X_temp, X_test, y_temp, y_test = train_test_split(X,y,test_size=0.1, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=1/9, random_state=42)

#Initialize the Random Forest model
rf_classifier = RandomForestClassifier(n_estimators=100, criterion = 'entropy', random_state=42)

#Fit the model on training data
rf_classifier.fit(X_train, y_train)

#Predict on validation data
y_pred_val = rf_classifier.predict(X_val)

#Predict on testing data
y_pred_test = rf_classifier.predict(X_test)

#Evaluate the model
print("Validation Accuracy:", accuracy_score(y_val, y_pred_val))
print(classification_report(y_val, y_pred_val))

print("Testing Accuracy:", accuracy_score(y_test, y_pred_test))
print(classification_report(y_val, y_pred_test))

# Predict probabilities for the test and val set
y_scores_val = rf_classifier.predict_proba(X_val)[:, 1]
y_scores_test = rf_classifier.predict_proba(X_test)[:, 1]

#Function to plot ROC Curve
def plot_roc_curve(y_true, y_score, title):
    fpr, tpr, thresholds = roc_curve(y_true, y_score)
    roc_auc = auc(fpr, tpr)

    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(title)
    plt.legend(loc="lower right")
    plt.show()

#Function to plot Precision-Recall Curve
def plot_precision_recall_curve(y_true, y_score, title):
    precision, recall, thresholds = precision_recall_curve(y_true, y_score)
    average_precision = average_precision_score(y_true, y_score)

    plt.figure()
    plt.step(recall, precision, where='post', label='Precision-Recall curve (area = %0.2f)' % average_precision)
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.ylim([0.0, 1.05])
    plt.xlim([0.0, 1.0])
    plt.title(title)
    plt.legend(loc="lower left")
    plt.show()

#Function to plot Confusion Matrix
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot()
    plt.show()

#Plot ROC Curve for validation set
plot_roc_curve(y_val, y_scores_val, "Validation ROC Curve Without Hospitlization Status")

#Plot ROC Curve for test set
plot_roc_curve(y_test, y_scores_test, "Testing ROC Curve Without Hospitlization Status")

#Plot Precision-Recall Curve for validation set
plot_precision_recall_curve(y_val, y_scores_val, "Validation Precision-Recall Curve Without Hospitalization Status")

#Plot Precision-Recall Curve for test set
plot_precision_recall_curve(y_test, y_scores_test, "Testing Precision-Recall Curve Without Hospitalization Status")

#Plot Confusion Matrix for validation set
print("Validation")
plot_confusion_matrix(y_val, y_pred_val)

#Plot Confusion Matrix for test set
print("Testing")
plot_confusion_matrix(y_test, y_pred_test)

feature_names = ['current_status_Laboratory-confirmed case', 'current_status_Probable Case','sex_Female',
                 'sex_Male', 'sex_Other', 'age_group_0 - 9 Years', 'age_group_10 - 19 Years', 'age_group_20 - 29 Years',
                 'age_group_30 - 39 Years', 'age_group_40 - 49 Years', 'age_group_50 - 59 Years', 'age_group_60 - 69 Years',
                 'age_group_70 - 79 Years', 'age_group_80+ Years', 'race_ethnicity_combined_American Indian/Alaska Native, Non-Hispanic',
                 'race_ethnicity_combined_Asian, Non-Hispanic', 'race_ethnicity_combined_Black, Non-Hispanic', 'race_ethnicity_combined_Hispanic/Latino',
                 'race_ethnicity_combined_Multiple/Other, Non-Hispanic', 'race_ethnicity_combined_Native Hawaiian/Other Pacific Islander, Non-Hispanic',
                 'race_ethnicity_combined_White, Non-Hispanic', 'icu_yn_Yes', 'medcond_yn_Yes']

#Feature Importance Plot
importances = rf_classifier.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(12, 8))
plt.title("Feature Importances on Full RF Model (No Hosp)")
plt.bar(range(len(importances)), importances[indices], color="r", align="center")
plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)
plt.xlim([-1, len(importances)])
plt.tight_layout()
plt.show()

start_time = time.time()
result = permutation_importance(
    rf_classifier, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2
)
elapsed_time = time.time() - start_time
print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

forest_importances = pd.Series(result.importances_mean, index=feature_names)

fig, ax = plt.subplots()
forest_importances.plot.bar(yerr=result.importances_std, ax=ax)
ax.set_title("Feature Importances Using Permutation on Full RF Model (No Hosp)")
ax.set_ylabel("Mean Accuracy Decrease")
fig.tight_layout()
plt.show()

explainer = shap.TreeExplainer(rf_classifier)
X_sample = shap.sample(X_train, 100)
shap_values_sample = explainer.shap_values(X_sample)

#Check shapes
print(f"SHAP values shape: {np.array(shap_values_sample).shape}")
print(f"X_train shape: {X_train.shape}")

shap_values_positive_class = shap_values_sample[:, :, 1]

shap.summary_plot(shap_values_positive_class, X_sample, feature_names=feature_names, plot_type="dot")

"""### 2. Drop 'icu_yn_yes'"""

df = pd.read_pickle("/content/drive/MyDrive/Machine Learning Project/Code/cdcdata.pkl")
columns_to_encode = ['current_status', 'sex', 'age_group', 'race_ethnicity_combined', 'hosp_yn', 'icu_yn', 'death_yn', 'medcond_yn']
df_encoded = one_hot_encoding_features(df, columns_to_encode)
cols_to_drop = ['cdc_case_earliest_dt', 'cdc_report_dt', 'pos_spec_dt', 'onset_dt', 'hosp_yn_No', 'icu_yn_No', 'death_yn_No', 'medcond_yn_No', 'icu_yn_Yes']
df_dropped = df_encoded.drop(cols_to_drop, axis=1)
df = df_dropped

features = df.drop('death_yn_Yes', axis=1)
labels = df['death_yn_Yes']
features_tensor = torch.tensor(features.values, dtype=torch.float32)
labels_tensor = torch.tensor(labels.values, dtype=torch.float32)

X = features_tensor.numpy()
y = labels_tensor.numpy()

X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=1/9, random_state=42)  # making the split 8:1:1

# Initialize the Random Forest model
rf_classifier = RandomForestClassifier(n_estimators=100, criterion = 'entropy', random_state=42)

# Fit the model on training data
rf_classifier.fit(X_train, y_train)

# Predict on validation data
y_pred_val = rf_classifier.predict(X_val)

# Predict on testing data
y_pred_test = rf_classifier.predict(X_test)

# Evaluate the model
print("Validation Accuracy:", accuracy_score(y_val, y_pred_val))
print(classification_report(y_val, y_pred_val))

print("Testing Accuracy:", accuracy_score(y_test, y_pred_test))
print(classification_report(y_val, y_pred_test))

# Predict probabilities for the test and val set
y_scores_val = rf_classifier.predict_proba(X_val)[:, 1]
y_scores_test = rf_classifier.predict_proba(X_test)[:, 1]

#Plot ROC Curve for validation set
plot_roc_curve(y_val, y_scores_val, "Validation ROC Curve Without ICU Admission Status")

#Plot ROC Curve for test set
plot_roc_curve(y_test, y_scores_test, "Testing ROC Curve Without ICU Admission Status")

#Plot Precision-Recall Curve for validation set
plot_precision_recall_curve(y_val, y_scores_val, "Validation Precision-Recall Curve Without ICU Admission Status")

#Plot Precision-Recall Curve for test set
plot_precision_recall_curve(y_test, y_scores_test, "Testing Precision-Recall Curve Without ICU Admission Status")

#Plot Confusion Matrix for validation set
print("Validation")
plot_confusion_matrix(y_val, y_pred_val)

#Plot Confusion Matrix for test set
print("Testing")
plot_confusion_matrix(y_test, y_pred_test)

feature_names = ['current_status_Laboratory-confirmed case', 'current_status_Probable Case','sex_Female',
                 'sex_Male', 'sex_Other', 'age_group_0 - 9 Years', 'age_group_10 - 19 Years', 'age_group_20 - 29 Years',
                 'age_group_30 - 39 Years', 'age_group_40 - 49 Years', 'age_group_50 - 59 Years', 'age_group_60 - 69 Years',
                 'age_group_70 - 79 Years', 'age_group_80+ Years', 'race_ethnicity_combined_American Indian/Alaska Native, Non-Hispanic',
                 'race_ethnicity_combined_Asian, Non-Hispanic', 'race_ethnicity_combined_Black, Non-Hispanic', 'race_ethnicity_combined_Hispanic/Latino',
                 'race_ethnicity_combined_Multiple/Other, Non-Hispanic', 'race_ethnicity_combined_Native Hawaiian/Other Pacific Islander, Non-Hispanic',
                 'race_ethnicity_combined_White, Non-Hispanic', 'hosp_yn_Yes', 'medcond_yn_Yes']

"""We see that with no ICU admission status,hospitalization status followed by pre-existing medical condtions and being 80+ are driving features."""

#Feature Importance Plot
importances = rf_classifier.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(12, 8))
plt.title("Feature Importances on Full RF Model (No ICU)")
plt.bar(range(len(importances)), importances[indices], color="r", align="center")
plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)
plt.xlim([-1, len(importances)])
plt.tight_layout()
plt.show()

start_time = time.time()
result = permutation_importance(
    rf_classifier, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2
)
elapsed_time = time.time() - start_time
print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

forest_importances = pd.Series(result.importances_mean, index=feature_names)

"""Interestingly enough, we see being a White-Non Hispanic is a very important feature."""

fig, ax = plt.subplots()
forest_importances.plot.bar(yerr=result.importances_std, ax=ax)
ax.set_title("Feature Importances Using Permutation on Full RF Model (No ICU)")
ax.set_ylabel("Mean Accuracy Decrease")
fig.tight_layout()
plt.show()

explainer = shap.TreeExplainer(rf_classifier)

X_sample = shap.sample(X_train, 100)
shap_values_sample = explainer.shap_values(X_sample)

#Check shapes
print(f"SHAP values shape: {np.array(shap_values_sample).shape}")
print(f"X_train shape: {X_train.shape}")

shap_values_positive_class = shap_values_sample[:, :, 1]

shap.summary_plot(shap_values_positive_class, X_sample, feature_names=feature_names, plot_type="dot")

"""### 3. Drop both 'icu_yn_Yes' and 'hosp_yn_Yes'"""

df = pd.read_pickle("/content/drive/MyDrive/Machine Learning Project/Code/cdcdata.pkl")
columns_to_encode = ['current_status', 'sex', 'age_group', 'race_ethnicity_combined', 'hosp_yn', 'icu_yn', 'death_yn', 'medcond_yn']
df_encoded = one_hot_encoding_features(df, columns_to_encode)
cols_to_drop = ['cdc_case_earliest_dt', 'cdc_report_dt', 'pos_spec_dt', 'onset_dt', 'hosp_yn_No', 'icu_yn_No', 'death_yn_No', 'medcond_yn_No', 'hosp_yn_Yes', 'icu_yn_Yes']
df_dropped = df_encoded.drop(cols_to_drop, axis=1)
df = df_dropped

features = df.drop('death_yn_Yes', axis=1)
labels = df['death_yn_Yes']
features_tensor = torch.tensor(features.values, dtype=torch.float32)
labels_tensor = torch.tensor(labels.values, dtype=torch.float32)

X = features_tensor.numpy()
y = labels_tensor.numpy()

X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=1/9, random_state=42)  # making the split 8:1:1

#Initialize the Random Forest model
rf_classifier = RandomForestClassifier(n_estimators=100, criterion = 'entropy', random_state=42)

#Fit the model on training data
rf_classifier.fit(X_train, y_train)

#Predict on validation data
y_pred_val = rf_classifier.predict(X_val)

#Predict on testing data
y_pred_test = rf_classifier.predict(X_test)

#Evaluate the model
print("Validation Accuracy:", accuracy_score(y_val, y_pred_val))
print(classification_report(y_val, y_pred_val))

print("Testing Accuracy:", accuracy_score(y_test, y_pred_test))
print(classification_report(y_val, y_pred_test))

#Predict probabilities for the test and val set
y_scores_val = rf_classifier.predict_proba(X_val)[:, 1]
y_scores_test = rf_classifier.predict_proba(X_test)[:, 1]

#Plot ROC Curve for validation set
plot_roc_curve(y_val, y_scores_val, "Validation ROC Curve Without Hospitalization & ICU Admission Status")

#Plot ROC Curve for test set
plot_roc_curve(y_test, y_scores_test, "Testing ROC Curve Without Hospitalization & ICU Admission Status")

#Plot Precision-Recall Curve for validation set
plot_precision_recall_curve(y_val, y_scores_val, "Validation Precision-Recall Curve Without Hospitalization & ICU Admission Status")

#Plot Precision-Recall Curve for test set
plot_precision_recall_curve(y_test, y_scores_test, "Testing Precision-Recall Curve Without Hospitalization & ICU Admission Status")

#Plot Confusion Matrix for validation set
print("Validation")
plot_confusion_matrix(y_val, y_pred_val)

#Plot Confusion Matrix for test set
print("Testing")
plot_confusion_matrix(y_test, y_pred_test)

feature_names = ['current_status_Laboratory-confirmed case', 'current_status_Probable Case','sex_Female',
                 'sex_Male', 'sex_Other', 'age_group_0 - 9 Years', 'age_group_10 - 19 Years', 'age_group_20 - 29 Years',
                 'age_group_30 - 39 Years', 'age_group_40 - 49 Years', 'age_group_50 - 59 Years', 'age_group_60 - 69 Years',
                 'age_group_70 - 79 Years', 'age_group_80+ Years', 'race_ethnicity_combined_American Indian/Alaska Native, Non-Hispanic',
                 'race_ethnicity_combined_Asian, Non-Hispanic', 'race_ethnicity_combined_Black, Non-Hispanic', 'race_ethnicity_combined_Hispanic/Latino',
                 'race_ethnicity_combined_Multiple/Other, Non-Hispanic', 'race_ethnicity_combined_Native Hawaiian/Other Pacific Islander, Non-Hispanic',
                 'race_ethnicity_combined_White, Non-Hispanic', 'medcond_yn_Yes']

"""With no ICU or hospitalization status, we see pre-existing medical conditions and old age play a major role in determining mortality."""

#Feature Importance Plot
importances = rf_classifier.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(12, 8))
plt.title("Feature Importances on Full RF Model (No ICU, No Hosp)")
plt.bar(range(len(importances)), importances[indices], color="r", align="center")
plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)
plt.xlim([-1, len(importances)])
plt.tight_layout()
plt.show()

start_time = time.time()
result = permutation_importance(
    rf_classifier, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2
)
elapsed_time = time.time() - start_time
print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

forest_importances = pd.Series(result.importances_mean, index=feature_names)

fig, ax = plt.subplots()
forest_importances.plot.bar(yerr=result.importances_std, ax=ax)
ax.set_title("Feature Importances Using Permutation on Full RF Model (No ICU, No Hosp)")
ax.set_ylabel("Mean Accuracy Decrease")
fig.tight_layout()
plt.show()

"""Lot of variety in feature importance based on permutation."""

explainer = shap.TreeExplainer(rf_classifier)

X_sample = shap.sample(X_train, 100)
shap_values_sample = explainer.shap_values(X_sample)

#Check shapes
print(f"SHAP values shape: {np.array(shap_values_sample).shape}")
print(f"X_train shape: {X_train.shape}")

shap_values_positive_class = shap_values_sample[:, :, 1]

shap.summary_plot(shap_values_positive_class, X_sample, feature_names=feature_names, plot_type="dot")

"""### 4. Fixing data imbalance

Since we see that the data imbalance impacts precison and recall in predicting death cases, we will make sure death and non-death cases are equal.
"""

#Majority class
false_data = df[df['death_yn_Yes'] == 0]
#Minority class
true_data = df[df['death_yn_Yes'] == 1]

undersampled_false_data = false_data.sample(n=len(true_data), random_state=42)
balanced_df = pd.concat([undersampled_false_data, true_data], ignore_index=True)
balanced_df = shuffle(balanced_df, random_state=42)

features = balanced_df.drop('death_yn_Yes', axis=1)
labels = balanced_df['death_yn_Yes']
features_tensor = torch.tensor(features.values, dtype=torch.float32)
labels_tensor = torch.tensor(labels.values, dtype=torch.float32)

X = features_tensor.numpy()
y = labels_tensor.numpy()

X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=1/9, random_state=42)  # making the split 8:1:1

#Initialize the RF model
rf_classifier = RandomForestClassifier(n_estimators=100, criterion = 'entropy', random_state=42)

#Fit the model on training data
rf_classifier.fit(X_train, y_train)

#Predict on validation data
y_pred_val = rf_classifier.predict(X_val)

#Predict on testing data
y_pred_test = rf_classifier.predict(X_test)

#Evaluate the model
print("Validation Accuracy:", accuracy_score(y_val, y_pred_val))
print(classification_report(y_val, y_pred_val))

print("Testing Accuracy:", accuracy_score(y_test, y_pred_test))
print(classification_report(y_val, y_pred_test))

#Predict probabilities for the test and val set
y_scores_val = rf_classifier.predict_proba(X_val)[:, 1]
y_scores_test = rf_classifier.predict_proba(X_test)[:, 1]

#Plot ROC Curve for validation set
plot_roc_curve(y_val, y_scores_val, "Validation ROC Curve Without Hospitialization & ICU Admission Status, Balanced Data")

#Plot ROC Curve for test set
plot_roc_curve(y_test, y_scores_test, "Testing ROC Curve Without Hospitialization & ICU Admission Status, Balanced Data")

"""A BIG improvement in PR curves and PR-AUC with balanced data"""

#Plot Precision-Recall Curve for validation set
plot_precision_recall_curve(y_val, y_scores_val, "Validation PR Curve Without Hospitialization & ICU Admission Status, Balanced Data")

#Plot Precision-Recall Curve for test set
plot_precision_recall_curve(y_test, y_scores_test, "Testing PR Curve Without Hospitialization & ICU Admission Status, Balanced Data")

"""Low amount of false negatives and positives now"""

#Plot Confusion Matrix for validation set
print("Validation")
plot_confusion_matrix(y_val, y_pred_val)

#Plot Confusion Matrix for test set
print("Testing")
plot_confusion_matrix(y_test, y_pred_test)

feature_names = ['current_status_Laboratory-confirmed case', 'current_status_Probable Case','sex_Female',
                 'sex_Male', 'sex_Other', 'age_group_0 - 9 Years', 'age_group_10 - 19 Years', 'age_group_20 - 29 Years',
                 'age_group_30 - 39 Years', 'age_group_40 - 49 Years', 'age_group_50 - 59 Years', 'age_group_60 - 69 Years',
                 'age_group_70 - 79 Years', 'age_group_80+ Years', 'race_ethnicity_combined_American Indian/Alaska Native, Non-Hispanic',
                 'race_ethnicity_combined_Asian, Non-Hispanic', 'race_ethnicity_combined_Black, Non-Hispanic', 'race_ethnicity_combined_Hispanic/Latino',
                 'race_ethnicity_combined_Multiple/Other, Non-Hispanic', 'race_ethnicity_combined_Native Hawaiian/Other Pacific Islander, Non-Hispanic',
                 'race_ethnicity_combined_White, Non-Hispanic', 'medcond_yn_Yes']

"""Medical conditions and old age once again driving features"""

#Feature Importance Plot
importances = rf_classifier.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(12, 8))
plt.title("Feature Importances on Full RF Model (No ICU, No Hosp, Balanced)")
plt.bar(range(len(importances)), importances[indices], color="r", align="center")
plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)
plt.xlim([-1, len(importances)])
plt.tight_layout()
plt.show()

start_time = time.time()
result = permutation_importance(
    rf_classifier, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2
)
elapsed_time = time.time() - start_time
print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

forest_importances = pd.Series(result.importances_mean, index=feature_names)

fig, ax = plt.subplots()
forest_importances.plot.bar(yerr=result.importances_std, ax=ax)
ax.set_title("Feature Importances Using Permutation on Full RF Model (No ICU, No Hosp, Balanced)")
ax.set_ylabel("Mean Accuracy Decrease")
fig.tight_layout()
plt.show()

"""Old age seem to me more important features than medical conditions"""

explainer = shap.TreeExplainer(rf_classifier)

X_sample = shap.sample(X_train, 10000)
shap_values_sample = explainer.shap_values(X_sample)

#Check shapes
print(f"SHAP values shape: {np.array(shap_values_sample).shape}")
print(f"X_train shape: {X_train.shape}")

shap_values_positive_class = shap_values_sample[:, :, 1]

shap.summary_plot(shap_values_positive_class, X_sample, feature_names=feature_names, plot_type="dot")

"""### Model Tuning

Now that we have an improved model and balanced dataset, we will play around with hyperparamters to determine the best RF model.
"""

#Define hyperparameters and their respective ranges to consider for the random search
param_distributions = {
    'n_estimators': [100, 200, 300, 400, 500],
    'criterion': ['gini', 'entropy', 'log_loss'],
    'max_depth': [10, 20, 30, 40, 50, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False],
    'class_weight': ['balanced', 'balanced_subsample']}

#Initialize the base model
rf_classifier = RandomForestClassifier(random_state=42)

#Initialize RandomizedSearchCV with the desired number of iterations and cross-validation folds
random_search_1 = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_distributions, n_iter=100, cv=StratifiedKFold(5),
    verbose=2, random_state=42, n_jobs=-1, scoring='accuracy')
random_search_2 = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_distributions, n_iter=100, cv=StratifiedKFold(5),
    verbose=2, random_state=42, n_jobs=-1, scoring='f1_weighted')

#Perform the RandomizedSearchCV to find the best model
best_rf_1 = random_search_1.fit(X_train, y_train)
best_rf_2 = random_search_2.fit(X_train, y_train)

#Best hyperparameters from RandomizedSearchCV
print("Best hyperparameters for RF (Acc):\n", best_rf_1.best_params_)
print("Best hyperparameters for RF (F-1):\n", best_rf_2.best_params_)

"""Better classification report, with better PR numbers in both testing and validation."""

#Evaluate the best model on the validation set
best_rf_model_1 = best_rf_1.best_estimator_
y_pred_val_1 = best_rf_model_1.predict(X_val)
y_pred_test_1 = best_rf_model_1.predict(X_test)

print("Validation Accuracy:", accuracy_score(y_val, y_pred_val_1))
print("Validation Classification Report:")
print(classification_report(y_val, y_pred_val))

print("Testing Accuracy:", accuracy_score(y_test, y_pred_test_1))
print("Testing Classification Report:")
print(classification_report(y_test, y_pred_test_1))

#Evaluate the best model on the validation set
best_rf_model = best_rf_2.best_estimator_
y_pred_val = best_rf_model.predict(X_val)
y_pred_test = best_rf_model.predict(X_test)

print("Validation Accuracy:", accuracy_score(y_val, y_pred_val))
print("Validation Classification Report:")
print(classification_report(y_val, y_pred_val))

print("Testing Accuracy:", accuracy_score(y_test, y_pred_test))
print("Testing Classification Report:")
print(classification_report(y_test, y_pred_test))

#Predict probabilities for the test and val set
y_scores_val = best_rf_model.predict_proba(X_val)[:, 1]
y_scores_test = best_rf_model.predict_proba(X_test)[:, 1]

#Plot ROC Curve for validation set
plot_roc_curve(y_val, y_scores_val, "Validation ROC Curve Without Hospitialization & ICU Admission Status, Balanced Data, Best HP")

#Plot ROC Curve for test set
plot_roc_curve(y_test, y_scores_test, "Testing ROC Curve Without Hospitialization & ICU Admission Status, Balanced Data, Best HP")

#Plot Precision-Recall Curve for validation set
plot_precision_recall_curve(y_val, y_scores_val, "Validation PR Curve Without Hospitialization & ICU Admission Status, Balanced Data, Best HP")

#Plot Precision-Recall Curve for test set
plot_precision_recall_curve(y_test, y_scores_test, "Testing PR Curve Without Hospitialization & ICU Admission Status, Balanced Data, Best HP")

#Plot Confusion Matrix for validation set
print("Validation")
plot_confusion_matrix(y_val, y_pred_val)

#Plot Confusion Matrix for test set
print("Testing")
plot_confusion_matrix(y_test, y_pred_test)

#Feature Importance Plot
importances = best_rf_model.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(12, 8))
plt.title("Feature Importances on Best RF Model")
plt.bar(range(len(importances)), importances[indices], color="r", align="center")
plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)
plt.xlim([-1, len(importances)])
plt.tight_layout()
plt.show()

start_time = time.time()
result = permutation_importance(
    best_rf_model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2
)
elapsed_time = time.time() - start_time
print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

forest_importances = pd.Series(result.importances_mean, index=feature_names)

fig, ax = plt.subplots()
forest_importances.plot.bar(yerr=result.importances_std, ax=ax)
ax.set_title("Feature Importances Using Permutation on Best RF Model")
ax.set_ylabel("Mean Accuracy Decrease")
fig.tight_layout()
plt.show()

explainer = shap.TreeExplainer(best_rf_model)

X_sample = shap.sample(X_train, 10000)
shap_values_sample = explainer.shap_values(X_sample)

#Check shapes
print(f"SHAP values shape: {np.array(shap_values_sample).shape}")
print(f"X_train shape: {X_train.shape}")

shap_values_positive_class = shap_values_sample[:, :, 1]

shap.summary_plot(shap_values_positive_class, X_sample, feature_names=feature_names, plot_type="dot")

print("Death")
shap.decision_plot(explainer.expected_value[0], shap_values_positive_class[0], feature_names=feature_names)

print("Non-Death")
shap.decision_plot(explainer.expected_value[1], shap_values_positive_class[1], feature_names)

"""### Recursive Feature Elimination with Cross Validation (RFECV)

Explore/see best features for RF
"""

df = pd.read_pickle("/content/drive/MyDrive/Machine Learning Project/Code/cdcdata.pkl")

columns_to_encode = ['current_status', 'sex', 'age_group', 'race_ethnicity_combined', 'hosp_yn', 'icu_yn', 'death_yn', 'medcond_yn']
cols_to_drop = ['cdc_case_earliest_dt', 'cdc_report_dt', 'pos_spec_dt', 'onset_dt', 'hosp_yn_No', 'icu_yn_No', 'death_yn_No', 'medcond_yn_No']

df_encoded = one_hot_encoding_features(df, columns_to_encode)
df_dropped = df_encoded.drop(cols_to_drop, axis=1)
df = df_dropped

#Majority class
false_data = df[df['death_yn_Yes'] == 0]
#Minority class
true_data = df[df['death_yn_Yes'] == 1]

undersampled_false_data = false_data.sample(n=len(true_data), random_state=42)
balanced_df = pd.concat([undersampled_false_data, true_data], ignore_index=True)
balanced_df = shuffle(balanced_df, random_state=42)

features = df.drop('death_yn_Yes', axis=1)
labels = df['death_yn_Yes']
features_tensor = torch.tensor(features.values, dtype=torch.float32)
labels_tensor = torch.tensor(labels.values, dtype=torch.float32)

X = features_tensor.numpy()
y = labels_tensor.numpy()

X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=1/9, random_state=42)  # making the split 8:1:1

#Since the features were converted to tensors and then to numpy,we assume they do not have the column names anymore.
#Make sure to have a list of your original feature names.
feature_names = list(df.drop('death_yn_Yes', axis=1).columns)

#Initialize the classifiers
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)

#Create RFECV models
rf_rfecv_1 = RFECV(estimator=rf_classifier, step=1, cv=StratifiedKFold(5), scoring='accuracy')
rf_rfecv_2 = RFECV(estimator=rf_classifier, step=1, cv=StratifiedKFold(5), scoring='f1_weighted')

#Fit RFECVs
rf_rfecv_1.fit(X_train, y_train)
rf_rfecv_2.fit(X_train, y_train)

#Get the features that contribute the most to the prediction
rf_best_features_1 = [feature_names[i] for i in range(len(feature_names)) if rf_rfecv_1.support_[i]]
rf_best_features_2 = [feature_names[i] for i in range(len(feature_names)) if rf_rfecv_2.support_[i]]

print(f"Random Forest Selected Features (Acc): {rf_best_features_1}")
print(f"Random Forest Selected Features (F-1): {rf_best_features_2}")

"""Try finding best HP for these features"""

df = pd.read_pickle("/content/drive/MyDrive/Machine Learning Project/Code/cdcdata.pkl")
columns_to_encode = ['current_status', 'sex', 'age_group', 'race_ethnicity_combined', 'hosp_yn', 'icu_yn', 'death_yn', 'medcond_yn']
df_encoded = one_hot_encoding_features(df, columns_to_encode)
cols_to_drop = ['cdc_case_earliest_dt', 'cdc_report_dt', 'pos_spec_dt', 'onset_dt', 'hosp_yn_No', 'icu_yn_No', 'death_yn_No', 'medcond_yn_No', 'sex_Male', 'sex_Other', 'current_status_Laboratory-confirmed case',
'current_status_Probable Case','race_ethnicity_combined_American Indian/Alaska Native, Non-Hispanic', 'race_ethnicity_combined_Asian, Non-Hispanic', 'race_ethnicity_combined_Black, Non-Hispanic', 'race_ethnicity_combined_Hispanic/Latino', 'race_ethnicity_combined_Native Hawaiian/Other Pacific Islander, Non-Hispanic', 'race_ethnicity_combined_Multiple/Other, Non-Hispanic' ]
df_dropped = df_encoded.drop(cols_to_drop, axis=1)
df = df_dropped

#Majority class
false_data = df[df['death_yn_Yes'] == 0]
#Minority class
true_data = df[df['death_yn_Yes'] == 1]

undersampled_false_data = false_data.sample(n=len(true_data), random_state=42)
balanced_df = pd.concat([undersampled_false_data, true_data], ignore_index=True)
balanced_df = shuffle(balanced_df, random_state=42)

features = df.drop('death_yn_Yes', axis=1)
labels = df['death_yn_Yes']
features_tensor = torch.tensor(features.values, dtype=torch.float32)
labels_tensor = torch.tensor(labels.values, dtype=torch.float32)

X = features_tensor.numpy()
y = labels_tensor.numpy()

X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=1/9, random_state=42)  # making the split 8:1:1

#Define hyperparameters and their respective ranges to consider for the random search
param_distributions = {
    'n_estimators': [100, 200, 300, 400, 500],
    'criterion': ['gini', 'entropy', 'log_loss'],
    'max_depth': [10, 20, 30, 40, 50, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False],
    'class_weight': ['balanced', 'balanced_subsample']}

#Initialize the base model
rf_classifier = RandomForestClassifier(random_state=42)

#Initialize RandomizedSearchCV with the desired number of iterations and cross-validation folds
random_search_1 = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_distributions, n_iter=100, cv=StratifiedKFold(5),
    verbose=2, random_state=42, n_jobs=-1, scoring='accuracy')
random_search_2 = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_distributions, n_iter=100, cv=StratifiedKFold(5),
    verbose=2, random_state=42, n_jobs=-1, scoring='f1_weighted')

#Perform the RandomizedSearchCV to find the best model
best_rf_1 = random_search_1.fit(X_train, y_train)
#best_rf_2 = random_search_2.fit(X_train, y_train)

#Best hyperparameters from RandomizedSearchCV
print("Best hyperparameters for RF (Acc):\n", best_rf_1.best_params_)
#print("Best hyperparameters for RF (F-1):\n", best_rf_2.best_params_)

#Evaluate the best model on the validation set
best_rf_model = best_rf_2.best_estimator_
y_pred_val = best_rf_model.predict(X_val)
y_pred_test = best_rf_model.predict(X_test)

print("Validation Accuracy:", accuracy_score(y_val, y_pred_val))
print("Validation Classification Report:")
print(classification_report(y_val, y_pred_val))

print("Testing Accuracy:", accuracy_score(y_test, y_pred_test))
print("Testing Classification Report:")
print(classification_report(y_test, y_pred_test))